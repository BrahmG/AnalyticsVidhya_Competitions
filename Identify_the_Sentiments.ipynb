{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Identify_the_Sentiments.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDKYzAsQm03t"
      },
      "source": [
        "##Identify the Sentiments\n",
        "Sentiment analysis is contextual mining of text which identifies and extracts subjective information in source material, and helping a business to understand the social sentiment of their brand, product or service while monitoring online conversations. Brands can use this data to measure the success of their products in an objective manner. In this challenge, you are provided with tweet data to predict sentiment on electronic products of netizens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ogtk9n-zi7LT"
      },
      "source": [
        "#Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import pickle\n",
        "%matplotlib inline\n",
        "import subprocess"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-r9uzKhjQTZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "05bd9834-6e37-450d-f480-c816b64066e8"
      },
      "source": [
        "!pip install bert-serving-client\n",
        "!pip install -U bert-serving-server[http]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-serving-client\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/09/aae1405378a848b2e87769ad89a43d6d71978c4e15534ca48e82e723a72f/bert_serving_client-1.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyzmq>=17.1.0 in /usr/local/lib/python3.6/dist-packages (from bert-serving-client) (19.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bert-serving-client) (1.18.5)\n",
            "Installing collected packages: bert-serving-client\n",
            "Successfully installed bert-serving-client-1.10.0\n",
            "Collecting bert-serving-server[http]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/bd/cab677bbd0c5fb08b72e468371d2bca6ed9507785739b4656b0b5470d90b/bert_serving_server-1.10.0-py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.18.5)\n",
            "Collecting GPUtil>=1.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pyzmq>=17.1.0 in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (19.0.2)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.1.0)\n",
            "Collecting flask-json; extra == \"http\"\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/2d/4c21d98b11f3a206fabbdd965b53a2ca3ee9fab7646c93cf36c060e8f1a4/Flask_JSON-0.3.4-py3-none-any.whl\n",
            "Collecting flask-cors; extra == \"http\"\n",
            "  Downloading https://files.pythonhosted.org/packages/69/7f/d0aeaaafb5c3c76c8d2141dbe2d4f6dca5d6c31872d4e5349768c1958abc/Flask_Cors-3.0.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: flask; extra == \"http\" in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: bert-serving-client; extra == \"http\" in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.10.0)\n",
            "Collecting flask-compress; extra == \"http\"\n",
            "  Downloading https://files.pythonhosted.org/packages/de/eb/6bb0f8cb872167752eab8b06b67724566342de873dcfd85faaf7761944d9/Flask-Compress-1.7.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (2.11.2)\n",
            "Requirement already satisfied, skipping upgrade: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (1.0.1)\n",
            "Collecting brotli\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/d3/7c98f05b7b9103e2f3a112ba42f269c798155b3e5404fb80bb8f823aaebe/Brotli-1.0.9-cp36-cp36m-manylinux1_x86_64.whl (357kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 16.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask; extra == \"http\"->bert-serving-server[http]) (1.1.1)\n",
            "Building wheels for collected packages: GPUtil, flask-compress\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7411 sha256=4b8630e5336ca5cf15da4cd6d1cd293b8bca68cb501eaf75d2bd53825b75ffa2\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "  Building wheel for flask-compress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flask-compress: filename=Flask_Compress-1.7.0-cp36-none-any.whl size=6833 sha256=8679c8cd7eca065101b502ae99d7b060639564f284d5399fc0cb0a2d3108cafe\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/b7/18/2b88ed33c5ef53868d1bfb0d3f2f351ae0143414734415bd06\n",
            "Successfully built GPUtil flask-compress\n",
            "Installing collected packages: GPUtil, flask-json, flask-cors, brotli, flask-compress, bert-serving-server\n",
            "Successfully installed GPUtil-1.4.0 bert-serving-server-1.10.0 brotli-1.0.9 flask-compress-1.7.0 flask-cors-3.0.9 flask-json-0.3.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OBkcl99jTXX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "234bdf14-3d24-4b87-a7b1-5dc9016a9615"
      },
      "source": [
        "# Download and unzip the pre-trained model\n",
        "!wget http://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
        "!unzip uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-26 20:40:02--  http://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 74.125.142.128, 74.125.20.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 407727028 (389M) [application/zip]\n",
            "Saving to: ‘uncased_L-12_H-768_A-12.zip’\n",
            "\n",
            "uncased_L-12_H-768_ 100%[===================>] 388.84M   120MB/s    in 3.2s    \n",
            "\n",
            "2020-10-26 20:40:06 (120 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n",
            "\n",
            "Archive:  uncased_L-12_H-768_A-12.zip\n",
            "   creating: uncased_L-12_H-768_A-12/\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V467EC-2jnHo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "588aa862-e918-4a4a-eab8-15aee6289529"
      },
      "source": [
        "!pwd \n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "sample_data  uncased_L-12_H-768_A-12  uncased_L-12_H-768_A-12.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JZltR5RjV-m"
      },
      "source": [
        "# Start the BERT server\n",
        "bert_command='bert-serving-start -model_dir /content/uncased_L-12_H-768_A-12'\n",
        "process=subprocess.Popen(bert_command.split(),stdout=subprocess.PIPE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8udk5e_j4qA"
      },
      "source": [
        "!nohup bert-serving-start -model_dir=./uncased_L-12_H-768_A-12 > out.file 2>&1 &"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieJUn4FApE1A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f15ac6e0-5ba0-455c-9fac-2cb690069b6f"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGqDJNAlpOqo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85508458-8fd5-48a6-d72f-16e50ba82f33"
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhuvgPlsotrM"
      },
      "source": [
        "from bert_serving.client import BertClient\n",
        "bc = BertClient()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQOzPF9ykXFU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "71cf2be0-1cf3-42a0-ee93-d94cab849e60"
      },
      "source": [
        "# Load the training dataset\n",
        "df = pd.read_csv('./train.csv')\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   id  label                                              tweet\n",
            "0   1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
            "1   2      0  Finally a transparant silicon case ^^ Thanks t...\n",
            "2   3      0  We love this! Would you go? #talk #makememorie...\n",
            "3   4      0  I'm wired I know I'm George I was made that wa...\n",
            "4   5      1  What amazing service! Apple won't even talk to...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXQ4w5EbkbhA"
      },
      "source": [
        "# Create a list of punctuation marks\n",
        "#Ref google\n",
        "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
        " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
        " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
        " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
        " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOiSOge3p3eg"
      },
      "source": [
        "# Code to replace punctuations with whitespaces\n",
        "def clean_text(x):\n",
        "    x = str(x)\n",
        "    for punct in puncts:\n",
        "        if punct in x:\n",
        "            x = x.replace(punct, ' ')\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQELiGr6p8Oy"
      },
      "source": [
        "df.tweet=df.tweet.apply(lambda x:clean_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh2PqGuvqDHW"
      },
      "source": [
        "df.tweet=df.tweet.apply(lambda x:re.sub(r'http\\S+','',x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH6K1ZE2qbQg"
      },
      "source": [
        "df.tweet=df.tweet.apply(lambda x:re.sub(r'@[\\w]*','',x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw8lthX9qjkI"
      },
      "source": [
        "df.tweet=df.tweet.apply(lambda x:x.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7krjOG75q1Ri"
      },
      "source": [
        "df.tweet=df.tweet.apply(lambda x:' '.join(x.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoqL2akdqpdP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3851b2a8-4f41-4b4f-fbde-c52cdd851d5c"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>fingerprint pregnancy test goo gl h1mfqv andro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>finally a transparant silicon case thanks to m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>we love this would you go talk makememories un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>i m wired i know i m george i was made that wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>what amazing service apple won t even talk to ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0  fingerprint pregnancy test goo gl h1mfqv andro...\n",
              "1   2      0  finally a transparant silicon case thanks to m...\n",
              "2   3      0  we love this would you go talk makememories un...\n",
              "3   4      0  i m wired i know i m george i was made that wa...\n",
              "4   5      1  what amazing service apple won t even talk to ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8fbSASFq6Ub",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "82ad23ba-260e-4208-be39-d9dda68f918d"
      },
      "source": [
        "# Compute embeddings for training tweets using Bert Client encode function\n",
        "# The model returns 768-dimensional embeddings\n",
        "tweets=df.tweet\n",
        "tweet_list=[word for word in tweets]\n",
        "embeddings=bc.encode(tweet_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=25\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
            "here is what you can do:\n",
            "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
            "- or, start a new server with a larger \"max_seq_len\"\n",
            "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rASEkyUFrJgp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5fdbbf3a-4a14-4d8c-ca65-1bec1de39ffa"
      },
      "source": [
        "print(embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7920, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZm3aD67rOaW"
      },
      "source": [
        "# save bert_train_new for reuse as it would take a really long time for conversion\n",
        "pickle_out=open('bert_train.pickle','wb')\n",
        "pickle.dump(embeddings,pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgKKwa2MrnAa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4fb4658a-e7d6-4881-dc1a-518136c07446"
      },
      "source": [
        "#loading test dataset\n",
        "df1=pd.read_csv('test.csv')\n",
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7921</td>\n",
              "      <td>I hate the new #iphone upgrade. Won't let me d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7922</td>\n",
              "      <td>currently shitting my fucking pants. #apple #i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7923</td>\n",
              "      <td>I'd like to puts some CD-ROMS on my iPad, is t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7924</td>\n",
              "      <td>My ipod is officially dead. I lost all my pict...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7925</td>\n",
              "      <td>Been fighting iTunes all night! I only want th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id                                              tweet\n",
              "0  7921  I hate the new #iphone upgrade. Won't let me d...\n",
              "1  7922  currently shitting my fucking pants. #apple #i...\n",
              "2  7923  I'd like to puts some CD-ROMS on my iPad, is t...\n",
              "3  7924  My ipod is officially dead. I lost all my pict...\n",
              "4  7925  Been fighting iTunes all night! I only want th..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCWSqjitrySX"
      },
      "source": [
        "df1.tweet=df1.tweet.apply(lambda x:clean_text(x))\n",
        "df1.tweet=df1.tweet.apply(lambda x:re.sub(r'http\\S+','',x))\n",
        "df1.tweet=df1.tweet.apply(lambda x:re.sub(r'@[\\w]*','',x))\n",
        "df1.tweet=df1.tweet.apply(lambda x:x.lower())\n",
        "df1.tweet=df1.tweet.apply(lambda x:' '.join(x.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XIjgrw0sCqX"
      },
      "source": [
        "# Compute embeddings for training tweets using Bert Client encode function\n",
        "# The model returns 768-dimensional embeddings\n",
        "test_tweets=df1.tweet\n",
        "test_tweet_list=[word for word in test_tweets]\n",
        "test_embeddings=bc.encode(test_tweet_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F5Zh5hQsPLR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89d525a4-37ab-46bc-c2f9-ba1c5f226c3e"
      },
      "source": [
        "print(test_embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1953, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3ErWb4_sTaN"
      },
      "source": [
        "# save bert_train_new for reuse as it would take a really long time for conversion\n",
        "pickle_out1=open('bert_test.pickle','wb')\n",
        "pickle.dump(test_embeddings,pickle_out1)\n",
        "pickle_out1.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alYajQ2hwVvR"
      },
      "source": [
        "##Spacy Word2Vec\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmaZF3mQsZah"
      },
      "source": [
        "pd.set_option('display.max_colwidth',100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa1EELiyxLZj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "9bddb740-6315-40bd-83c2-0ba842249219"
      },
      "source": [
        "!python -m spacy download en_vectors_web_lg\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_vectors_web_lg==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_vectors_web_lg-2.1.0/en_vectors_web_lg-2.1.0.tar.gz (661.8MB)\n",
            "\u001b[K     |████████████████████████████████| 661.8MB 1.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.0.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from en_vectors_web_lg==2.1.0) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (1.18.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (0.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (3.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (2.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (50.3.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (2.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (2020.6.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (3.3.1)\n",
            "Building wheels for collected packages: en-vectors-web-lg\n",
            "  Building wheel for en-vectors-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-vectors-web-lg: filename=en_vectors_web_lg-2.1.0-cp36-none-any.whl size=663461749 sha256=c20f1de62ff791030b4a8e786320f863cb00ba9b178fbda72d1fdea6b197fbf6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c0k7l_x1/wheels/ce/3e/83/59647d0b4584003cce18fb68ecda2866e7c7b2722c3ecaddaf\n",
            "Successfully built en-vectors-web-lg\n",
            "Installing collected packages: en-vectors-web-lg\n",
            "Successfully installed en-vectors-web-lg-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_vectors_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQBnF_B5yljx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "4e0e9a1b-9410-4d5f-d9a0-e83018caf97c"
      },
      "source": [
        "!python -m spacy download en_vectors_web_lg\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_vectors_web_lg==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_vectors_web_lg-2.1.0/en_vectors_web_lg-2.1.0.tar.gz#egg=en_vectors_web_lg==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied: spacy<3.0.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from en_vectors_web_lg==2.1.0) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (1.18.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (50.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (0.8.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (2.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->en_vectors_web_lg==2.1.0) (3.3.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_vectors_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBF0Uftdwf3P"
      },
      "source": [
        "import spacy\n",
        "# Load the largest english language vector collection from Spacy\n",
        "nlp = spacy.load('en_vectors_web_lg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLUxpMvIwjF_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f0938899-32c8-4de3-f6da-88e40a86299e"
      },
      "source": [
        "df['label'].value_counts(normalize = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.744192\n",
              "1    0.255808\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdMCTk-KwwDs"
      },
      "source": [
        "# Function to lemmatize the tokens to their basic forms to normalize the tweet text\n",
        "# and focus on key words for the classification tasks\n",
        "\n",
        "def lemmatization(texts):\n",
        "    output = []\n",
        "    for i in texts:\n",
        "        s = [token.lemma_ for token in nlp(i)]\n",
        "        output.append(' '.join(s))\n",
        "    return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJMM198HxhMa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "479442b6-dc15-4dcc-f526-719bdc8b14a9"
      },
      "source": [
        "%%time\n",
        "df.tweet=lemmatization(df.tweet)\n",
        "\n",
        "df.tweet=df.tweet.str.replace('-PRON-','')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.35 s, sys: 4.36 ms, total: 1.35 s\n",
            "Wall time: 1.36 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMoOp8dxxtQW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9f37ac5b-6813-44cd-dd43-f83c6862cf2e"
      },
      "source": [
        "%%time\n",
        "df1.tweet=lemmatization(df1.tweet)\n",
        "df1.tweet=df1.tweet.str.replace('-PRON-','')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 318 ms, sys: 84 µs, total: 318 ms\n",
            "Wall time: 318 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkSCDPD50Qlb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "14f6ef49-1ccd-4da5-b061-dfaa22237986"
      },
      "source": [
        "nlp('having').vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.1235e-01,  2.1697e-01, -2.1090e-01,  1.6637e-01,  9.6581e-02,\n",
              "       -3.5390e-02,  3.2933e-01, -2.7312e-01, -1.5304e-02,  2.6093e+00,\n",
              "        1.3405e-01,  3.7844e-04,  5.4900e-02, -2.5173e-01, -3.5485e-01,\n",
              "       -3.7260e-01, -1.7240e-03,  1.1956e+00, -4.1293e-01,  3.5877e-01,\n",
              "        5.1265e-03, -2.9626e-01, -2.4748e-01,  1.6286e-01,  7.5768e-02,\n",
              "        1.3535e-02, -7.9647e-02, -4.9073e-01, -1.0783e-01, -6.3812e-02,\n",
              "       -1.3171e-01,  1.8626e-01,  2.4554e-01,  2.5685e-01,  3.0148e-01,\n",
              "       -4.8167e-01,  4.0285e-01, -4.7838e-02, -8.0964e-02, -5.6645e-01,\n",
              "        2.1666e-01,  1.1220e-01,  1.5485e-02,  3.1444e-01, -4.7426e-01,\n",
              "        3.0210e-01, -3.6470e-01, -3.4347e-01,  9.9283e-02, -8.5861e-02,\n",
              "       -8.2277e-02, -2.5866e-02, -4.7161e-02, -2.1301e-01,  2.6880e-01,\n",
              "        1.8113e-01, -2.0620e-01, -2.4319e-02, -1.5963e-01,  8.6472e-02,\n",
              "        1.8116e-01,  1.2205e-01, -4.6879e-01,  2.7622e-01,  3.7899e-02,\n",
              "        4.4370e-03,  2.6413e-01,  2.2721e-01, -1.7805e-02,  2.7563e-01,\n",
              "        2.6386e-01,  1.7431e-01, -6.1444e-02, -2.1381e-02, -2.7438e-02,\n",
              "        1.6243e-01,  2.8102e-01, -3.5839e-02,  1.7901e-01,  3.2328e-01,\n",
              "       -1.1513e-01,  1.3440e-01, -1.8181e-01, -5.0755e-01,  1.9801e-02,\n",
              "       -3.0611e-01,  2.8132e-01, -3.1478e-02,  1.8076e-01, -8.5850e-03,\n",
              "       -1.4519e-02,  2.8539e-02, -2.0772e-01,  1.8872e-01, -3.3428e-02,\n",
              "        2.5718e-01,  4.4756e-01, -2.1874e-01,  4.7900e-02,  1.4013e-01,\n",
              "       -3.2908e-01,  3.1017e-02, -1.5771e-02, -2.7796e-01,  2.0601e-01,\n",
              "       -1.3484e+00, -1.3698e-01, -8.7260e-02, -6.8283e-02,  1.7768e-01,\n",
              "        1.2368e-01,  2.2966e-01,  3.7684e-03,  3.6778e-02, -1.9610e-01,\n",
              "       -4.0696e-01, -1.2112e-01,  2.8510e-01, -2.4706e-01,  4.0122e-01,\n",
              "        2.9606e-01,  1.7297e-01,  5.7350e-01,  6.2956e-02,  3.7901e-01,\n",
              "       -1.9420e-02, -1.4721e-01, -3.1434e-01, -2.4116e-01, -2.2703e-01,\n",
              "       -1.5893e-03,  1.8312e-01, -3.2423e-01,  1.5497e-01,  3.3933e-01,\n",
              "       -2.3480e-01,  1.5851e-02,  2.7963e-01,  1.8745e-02, -1.5975e-01,\n",
              "       -1.5019e+00,  5.0632e-02,  3.6933e-02,  1.0450e-01, -7.0496e-02,\n",
              "       -2.0645e-01, -7.0083e-02, -8.1474e-02,  1.8476e-01, -9.9499e-02,\n",
              "       -3.0478e-01,  7.6468e-02, -2.3014e-01, -7.0870e-02, -7.0931e-02,\n",
              "        8.1447e-02,  8.0975e-02,  4.3891e-01,  1.9877e-01, -3.2176e-01,\n",
              "        2.1967e-01, -5.7821e-01,  3.0394e-01, -1.2663e-01, -1.0427e-01,\n",
              "       -2.4780e-01,  2.6204e-01,  6.2570e-02,  9.1614e-02,  1.8825e-02,\n",
              "       -2.6012e-01, -4.1146e-01,  2.7580e-01, -4.9186e-03, -8.3340e-02,\n",
              "       -1.1895e-01, -3.8721e-01,  4.7886e-02,  9.9593e-02, -2.6970e-01,\n",
              "       -7.3007e-03, -3.7161e-01, -6.0079e-01,  4.3112e-02, -1.7589e-01,\n",
              "       -3.2411e-01, -2.6899e-01,  7.3743e-01, -1.7653e-01, -1.7557e-01,\n",
              "        1.6940e-01,  1.9966e-02, -1.3267e-01,  5.9843e-01,  2.3689e-01,\n",
              "        1.1431e-02, -8.2624e-02,  2.5213e-01, -5.1019e-01,  1.7412e-01,\n",
              "        4.0625e-01, -1.0041e-03,  2.7558e-01,  7.2856e-03,  3.6192e-01,\n",
              "        9.3313e-02, -4.0080e-01, -2.0661e-01, -5.1045e-03,  1.5150e-01,\n",
              "       -2.6760e-01,  2.6065e-01, -3.8441e-01, -4.5888e-02, -3.4107e-01,\n",
              "        2.3661e-01, -2.5816e-01, -1.6351e-01,  1.4184e-01,  1.7698e-01,\n",
              "       -1.1873e-01, -7.8805e-02, -2.2065e-01,  2.1354e-01,  8.3310e-02,\n",
              "       -1.3151e-02,  1.6681e-01,  6.7123e-02, -1.4861e-01, -7.7549e-02,\n",
              "        1.3314e-01, -2.5016e-01,  3.0317e-02, -4.2529e-02,  2.6820e-01,\n",
              "       -2.5129e-01,  1.7177e-01,  8.6223e-02, -1.0212e-01,  1.1251e-01,\n",
              "       -6.6374e-02,  3.7500e-02,  2.6159e-01,  6.3398e-01, -7.4445e-02,\n",
              "       -2.2132e-03, -3.4139e-02,  1.3005e-01, -3.4528e-01,  2.7955e-02,\n",
              "        1.4248e-01, -2.3346e-01,  3.2881e-01,  1.5303e-01,  1.7503e-01,\n",
              "        1.3949e-01, -5.0988e-02, -9.5092e-02, -5.1364e-02,  2.5831e-01,\n",
              "        3.1437e-01,  4.3509e-01, -3.9043e-01,  5.4367e-01,  2.8549e-01,\n",
              "        7.8270e-01, -2.2442e-02,  1.1466e-01,  5.1672e-01, -2.9182e-01,\n",
              "       -4.3049e-02, -7.7364e-02, -3.9407e-01, -2.5879e-01, -3.4362e-01,\n",
              "        2.9721e-01, -2.6811e-01,  8.9689e-02,  1.2101e-01,  5.0895e-01,\n",
              "        2.8325e-01,  4.3377e-01,  9.8544e-02,  5.9706e-02, -1.3283e-02,\n",
              "       -1.0903e-01,  2.1455e-01, -2.9188e-01,  1.6256e-01,  2.1777e-01,\n",
              "       -1.4039e-01, -8.1819e-03, -3.7918e-01, -2.1583e-01, -1.8292e-01,\n",
              "       -5.0702e-02, -7.3112e-02, -1.6639e-03, -1.7232e-02,  3.5350e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0XBdVmtz3E3"
      },
      "source": [
        "# Convert cleaned tweets into Spacy word vectors\n",
        "# The model returns 300-dimensional embeddings\n",
        "\n",
        "tweets=df.tweet\n",
        "tweet_list=[nlp(word).vector for word in tweets]\n",
        "X_tr=np.array(tweet_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeQPBgwt0JVK"
      },
      "source": [
        "test_tweets = df1.tweet\n",
        "test_word_vec = [nlp(word).vector for word in test_tweets]\n",
        "X_te = np.array(test_word_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgANz8J80OoK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "212107d9-00b1-403d-f1e5-77afc66b1e97"
      },
      "source": [
        "print(X_tr.shape, X_te.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7920, 300) (1953, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moSOHLy70UU8"
      },
      "source": [
        "# Save Spacy_train_new\n",
        "pickle_out = open(\"Spacy_train.pickle\",\"wb\")\n",
        "pickle.dump(X_tr, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "# Save Spacy_test_new\n",
        "pickle_out = open(\"Spacy_test.pickle\",\"wb\")\n",
        "pickle.dump(X_te, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NCHDz7N0ah4"
      },
      "source": [
        "# Additional 'Optional' step for text normalization\n",
        "# Import spaCy's language model\n",
        "nlp1 = spacy.load('en', disable=['parser', 'ner'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWx5_44-2WXI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "601710b8-1e32-4bf2-e4e7-6ee7325b7aea"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L13TF3_s3yB6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "27e2de1a-6ad8-4d3e-cbdc-2c9f1ca71e28"
      },
      "source": [
        "!pip install tensorflow-hub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (3.12.4)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.18.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-hub) (50.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VzZsDuQ3fFo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "eabd9c60-f3fc-4ece-d390-3f6c018f32ac"
      },
      "source": [
        "!pip install tensorflow_gpu==1.5.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_gpu==1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/8b/094add4d2d667ddfef867285e2c16ac4fee6a1d51cece87d6d490b6e5571/tensorflow_gpu-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (201.9MB)\n",
            "\u001b[K     |████████████████████████████████| 201.9MB 85kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.5.0) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.5.0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.5.0) (0.35.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.5.0) (0.10.0)\n",
            "Collecting tensorflow-tensorboard<1.6.0,>=1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/fa/91c06952517b4f1bc075545b062a4112e30cebe558a6b962816cb33efa27/tensorflow_tensorboard-1.5.1-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 50.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.5.0) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow_gpu==1.5.0) (50.3.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow_gpu==1.5.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow_gpu==1.5.0) (3.3.3)\n",
            "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow_gpu==1.5.0) (1.5.0)\n",
            "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow_gpu==1.5.0) (0.9999999)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow_gpu==1.5.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow_gpu==1.5.0) (3.3.1)\n",
            "Installing collected packages: tensorflow-tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-gpu 1.2.0\n",
            "    Uninstalling tensorflow-gpu-1.2.0:\n",
            "      Successfully uninstalled tensorflow-gpu-1.2.0\n",
            "Successfully installed tensorflow-gpu-1.5.0 tensorflow-tensorboard-1.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUZXDMdn2uLI"
      },
      "source": [
        "import tensorflow_hub as hub\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMj8IsTm2y4-"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTQILbX94DoW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b496d7f2-93ac-4862-fcce-7cc735e72fef"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRsGkt884E6G"
      },
      "source": [
        "def elmo_convert(x):\n",
        "  embeddings=elmo(x.tolist(),signature='default',as_dict=True)['elmo']\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.tables_initializer())\n",
        "    # return average of ELMo features\n",
        "    return sess.run(tf.reduce_mean(embeddings,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xhocv0P351e6"
      },
      "source": [
        "# Creating batches of 100 tweets to feed into elmo model at a time as it consumes high computation power and memory \n",
        "list_train = [df[i:i+100] for i in range(0,df.shape[0],100)]\n",
        "list_test = [df1[i:i+100] for i in range(0,df1.shape[0],100)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m4DL4cH6EUz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64ab5d06-51ba-405c-92cf-a0a2b9dc458d"
      },
      "source": [
        "# Extract ELMo embeddings\n",
        "elmo_train=[elmo_convert(x['tweet']) for x in list_train]\n",
        "elmo_test=[elmo_convert(x['tweet']) for x in list_test]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhFbUg9C6Uci"
      },
      "source": [
        "# Concatenating converted batches into single array of train and test dataset embeddings\n",
        "elmo_train_new=np.concatenate(elmo_train,axis=0)\n",
        "elmo_test_new=np.concatenate(elmo_test,axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mEUnYNL6lH_"
      },
      "source": [
        "# save elmo_train\n",
        "pickle_out = open(\"elmo_train.pickle\",\"wb\")\n",
        "pickle.dump(elmo_train_new, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "# save elmo_test\n",
        "pickle_out = open(\"elmo_test.pickle\",\"wb\")\n",
        "pickle.dump(elmo_test_new, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8DYsJniBJ2d"
      },
      "source": [
        "df_train=pd.read_csv('train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZogPM4t772B"
      },
      "source": [
        "#adding tweet length\n",
        "df_train['tweet_len_total']=df_train.tweet.str.len()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8V1SL0m_f2w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "14178691-37d8-4f39-f131-01c8269507e6"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_len_total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
              "      <td>128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>What amazing service! Apple won't even talk to...</td>\n",
              "      <td>124</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...  tweet_len_total\n",
              "0   1  ...              128\n",
              "1   2  ...              131\n",
              "2   3  ...              123\n",
              "3   4  ...              112\n",
              "4   5  ...              124\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzGX4VNu_nl2"
      },
      "source": [
        "#punctuation length as  a feature\n",
        "# Function to calculate the total length of punctuation marks in a tweet\n",
        "def puncts_len(x):\n",
        "    punct_list = []\n",
        "    x = str(x)\n",
        "    for punct in puncts:\n",
        "        for char in x:\n",
        "            if punct==char:\n",
        "                punct_list.append(punct)\n",
        "    return len(punct_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBdRW-Y_9Qr"
      },
      "source": [
        "df_train['punc_len']=df_train.tweet.apply(lambda x:puncts_len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3AjQoFTAUKP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "13bf06e9-7ebe-4171-86c1-b29aab69d9d9"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_len_total</th>\n",
              "      <th>punc_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
              "      <td>128</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
              "      <td>131</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
              "      <td>123</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
              "      <td>112</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>What amazing service! Apple won't even talk to...</td>\n",
              "      <td>124</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label  ... tweet_len_total  punc_len\n",
              "0   1      0  ...             128        16\n",
              "1   2      0  ...             131        17\n",
              "2   3      0  ...             123        18\n",
              "3   4      0  ...             112        17\n",
              "4   5      1  ...             124         5\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsLb11kuAVvn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "f2239f64-58b4-4e76-d8b9-ed6b3ad5e723"
      },
      "source": [
        "df_train.punc_len.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    7920.000000\n",
              "mean       13.956692\n",
              "std         8.406173\n",
              "min         0.000000\n",
              "25%         7.000000\n",
              "50%        15.000000\n",
              "75%        18.000000\n",
              "max        59.000000\n",
              "Name: punc_len, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaqM89FBAwYn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "c20dcb47-1788-421c-a9fa-83d8eb124df3"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7920 entries, 0 to 7919\n",
            "Data columns (total 5 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   id               7920 non-null   int64 \n",
            " 1   label            7920 non-null   int64 \n",
            " 2   tweet            7920 non-null   object\n",
            " 3   tweet_len_total  7920 non-null   int64 \n",
            " 4   punc_len         7920 non-null   int64 \n",
            "dtypes: int64(4), object(1)\n",
            "memory usage: 309.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygEPGbCvAxx1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7851f550-87a2-4a39-a64e-afc3c9b5ed04"
      },
      "source": [
        "bins=1.15**(np.arange(0,30))\n",
        "plt.hist(df_train.punc_len,bins=bins,alpha=0.8)\n",
        "plt.hist(df_train[df_train.label==1]['punc_len'],bins=bins,alpha=0.8)\n",
        "plt.legend(('pos','neg'))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n3l7XRPBC1V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "08ed55e7-28c5-4cc2-9c94-8f19e9d6eade"
      },
      "source": [
        "bins = 1.15**(np.arange(0,50))\n",
        "plt.hist(df_train['tweet_len_total'],bins=bins,alpha=0.8)\n",
        "plt.hist(df_train[df_train['label']==1]['tweet_len_total'],bins=bins,alpha=0.8)\n",
        "plt.legend(('pos','neg'))\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViUoQoqACSpx"
      },
      "source": [
        "df_train.to_csv('more_features_train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FZhujbgCpG5"
      },
      "source": [
        "# Similarly for test dataset loading new dataframe\n",
        "df_test= pd.read_csv('test.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJs4cAZaCtlb"
      },
      "source": [
        "#adding tweet length\n",
        "df_test['tweet_len_total']=df_test.tweet.str.len()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64h9FRy2C1mr"
      },
      "source": [
        "df_test['punc_len']=df_test.tweet.apply(lambda x:puncts_len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtRfTI32C5uU"
      },
      "source": [
        "df_test.to_csv('more_features_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6bjGCHBDD1v"
      },
      "source": [
        "# Load Spacy_train Vectors\n",
        "pickle_in = open(\"Spacy_train.pickle\",\"rb\")\n",
        "spacy_train = pickle.load(pickle_in)\n",
        "# Load Spacy_test Vectors\n",
        "pickle_in = open(\"Spacy_test.pickle\",\"rb\")\n",
        "spacy_test = pickle.load(pickle_in)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atY3xTfZDdTB"
      },
      "source": [
        "# Load BERT_train Vectors\n",
        "pickle_in = open(\"bert_train.pickle\",\"rb\")\n",
        "bert_train = pickle.load(pickle_in)\n",
        "\n",
        "# Load BERT_test Vectors\n",
        "pickle_in = open(\"bert_test.pickle\",\"rb\")\n",
        "bert_test = pickle.load(pickle_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVImBnUEDk8x"
      },
      "source": [
        "# Load ELMo_train Vectors\n",
        "pickle_in = open(\"elmo_train.pickle\",\"rb\")\n",
        "elmo_train = pickle.load(pickle_in)\n",
        "\n",
        "# Load ELMo_test Vectors\n",
        "pickle_in = open(\"elmo_test.pickle\",\"rb\")\n",
        "elmo_test = pickle.load(pickle_in)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0HRspfEDm_M"
      },
      "source": [
        "# Create Spacy + BERT Vectors\n",
        "sb_train=np.hstack((spacy_train,bert_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RdCNCSkDv0X"
      },
      "source": [
        "sb_test=np.hstack((spacy_test,bert_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK3SX545D3oR"
      },
      "source": [
        "# save spacy_bert_train\n",
        "pickle_out = open(\"Spacy_bert_train.pickle\",\"wb\")\n",
        "pickle.dump(sb_train, pickle_out)\n",
        "pickle_out.close()\n",
        "# save Spacy_bert_test\n",
        "pickle_out = open(\"Spacy_bert_test.pickle\",\"wb\")\n",
        "pickle.dump(sb_test, pickle_out)\n",
        "pickle_out.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhGJthYwEBfl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e8b6dc3-5c18-4075-b4a8-ee4ded238f42"
      },
      "source": [
        "# Create BERT + ELMo Vectors\n",
        "bert_elmo_train = np.hstack((bert_train, elmo_train))\n",
        "bert_elmo_test = np.hstack((bert_test, elmo_test))\n",
        "\n",
        "print(bert_elmo_train.shape, bert_elmo_test.shape)\n",
        "\n",
        "# save bert_elmo_train\n",
        "pickle_out = open(\"bert_elmo_train.pickle\",\"wb\")\n",
        "pickle.dump(bert_elmo_train, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "# save bert_elmo_test\n",
        "pickle_out = open(\"bert_elmo_test.pickle\",\"wb\")\n",
        "pickle.dump(bert_elmo_test, pickle_out)\n",
        "pickle_out.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7920, 1792) (1953, 1792)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQPTxe61EErx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ecf8b628-18bd-4799-860d-cfe94d83930d"
      },
      "source": [
        "# Create Spacy + ELMo Vectors\n",
        "spacy_elmo_train = np.hstack((spacy_train, elmo_train))\n",
        "spacy_elmo_test = np.hstack((spacy_test, elmo_test))\n",
        "\n",
        "print(spacy_elmo_train.shape, spacy_elmo_test.shape)\n",
        "\n",
        "# save Spacy_elmo_train\n",
        "pickle_out = open(\"Spacy_elmo_train.pickle\",\"wb\")\n",
        "pickle.dump(spacy_elmo_train, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "# save Spacy_elmo_test\n",
        "pickle_out = open(\"Spacy_elmo_test.pickle\",\"wb\")\n",
        "pickle.dump(spacy_elmo_test, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7920, 1324) (1953, 1324)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll-9V2whEG47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e20370e6-a2b0-4840-fa22-c7e280f0efb2"
      },
      "source": [
        "\n",
        "# Create Spacy + BERT + ELMo Vectors\n",
        "spacy_bert_elmo_train = np.hstack((spacy_train, bert_train, elmo_train))\n",
        "spacy_bert_elmo_test = np.hstack((spacy_test, bert_test, elmo_test))\n",
        "\n",
        "print(spacy_bert_elmo_train.shape, spacy_bert_elmo_test.shape)\n",
        "\n",
        "# save Spacy_bert_elmo_train\n",
        "pickle_out = open(\"Spacy_bert_elmo_train.pickle\",\"wb\")\n",
        "pickle.dump(spacy_bert_elmo_train, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "# save Spacy_bert_elmo_test\n",
        "pickle_out = open(\"Spacy_bert_elmo_test.pickle\",\"wb\")\n",
        "pickle.dump(spacy_bert_elmo_test, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7920, 2092) (1953, 2092)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RzGYUg2EIWG"
      },
      "source": [
        "# Load any variation of word embeddings from Spacy, BERT and ELMo and assign it to X variable\n",
        "pickle_in = open(\"Spacy_bert_elmo_train.pickle\",\"rb\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4Eh27HLEOco"
      },
      "source": [
        "X=pickle.load(pickle_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgrtZQhZESP4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e83747ee-b360-481b-abd8-91d8c4a7bfd9"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7920, 2092)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhgNG_MNETkU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "127f0aa1-dfa2-4198-e946-7fe137816751"
      },
      "source": [
        "# Load the training dataset into a dataframe\n",
        "df = pd.read_csv('more_features_train.csv')\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0  id  ...  tweet_len_total punc_len\n",
            "0           0   1  ...              128       16\n",
            "1           1   2  ...              131       17\n",
            "2           2   3  ...              123       18\n",
            "3           3   4  ...              112       17\n",
            "4           4   5  ...              124        5\n",
            "\n",
            "[5 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttp2oSL3EYBr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bf4a017e-7615-4bbf-99e8-269fc983eaab"
      },
      "source": [
        "df.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5894\n",
              "1    2026\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySOsSYYKEbBA"
      },
      "source": [
        "y=df.label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwfDucfEFBzR"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "mms=MinMaxScaler(feature_range=(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ulogj-VFP5v"
      },
      "source": [
        "tweet_len=mms.fit_transform(np.array(df.tweet_len_total).reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPbfg3EHFP2n"
      },
      "source": [
        "punc_len=mms.fit_transform(np.array(df.punc_len).reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw5BVRtnFPyt"
      },
      "source": [
        "final_X=np.hstack((X,tweet_len,punc_len))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab6avHXXFPu5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c433c959-dc4d-4ea9-cd6e-52883fbfb482"
      },
      "source": [
        "print(final_X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7920, 2094)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz9gfNFYE0fV"
      },
      "source": [
        "# Split the training dataset into train and test subsets\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xofMY-z4E4My"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(final_X, y, test_size=0.1, random_state=95)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51pfqUclF39r"
      },
      "source": [
        "#we can apply any classification model\n",
        "from sklearn import svm \n",
        "svc=svm.LinearSVC()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbWB0qnbGIC4"
      },
      "source": [
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bloIMfMiGMVO"
      },
      "source": [
        "text_clf=Pipeline([('clf',svc)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPMTSPZjGULE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "fe4fee75-843d-4729-a896-18dc6df44cbc"
      },
      "source": [
        "text_clf.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('clf',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54yruEKsGXoj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "e0f2753c-601d-4584-de3e-335326f6ec6b"
      },
      "source": [
        "# Make predictions\n",
        "predictions = text_clf.predict(X_test)\n",
        "print(predictions)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1\n",
            " 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
            " 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1\n",
            " 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0\n",
            " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1\n",
            " 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0\n",
            " 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1\n",
            " 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1\n",
            " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0\n",
            " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0\n",
            " 1 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 1\n",
            " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1\n",
            " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1\n",
            " 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU7pPS3lGagN"
      },
      "source": [
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sB3oahLGicH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6d95217a-4d1d-4bdb-a68b-ed829064194e"
      },
      "source": [
        "metrics.confusion_matrix(y_test,predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[545,  38],\n",
              "       [ 61, 148]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiGMmBtwGsJI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "04e4c65f-674a-41fb-8d59-21e2eb865fdd"
      },
      "source": [
        "metrics.classification_report(y_test,predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n           0       0.90      0.93      0.92       583\\n           1       0.80      0.71      0.75       209\\n\\n    accuracy                           0.88       792\\n   macro avg       0.85      0.82      0.83       792\\nweighted avg       0.87      0.88      0.87       792\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75bdPXu6Gxgo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c9e760a-609a-49df-f244-085e89d696c9"
      },
      "source": [
        "metrics.accuracy_score(y_test,predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRjH33vKG1Mb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "45592812-a8e9-48fc-f6ad-f6e6c362f8f9"
      },
      "source": [
        "# Loading test dataset\n",
        "df1 = pd.read_csv('more_features_test.csv')\n",
        "print(df1.head())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0    id  ... tweet_len_total  punc_len\n",
            "0           0  7921  ...              77         6\n",
            "1           1  7922  ...             115        13\n",
            "2           2  7923  ...             104         9\n",
            "3           3  7924  ...             129         4\n",
            "4           4  7925  ...              70         6\n",
            "\n",
            "[5 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X9rHvttG5FM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9757596d-fe0e-4561-8e71-b0d72e26c7ca"
      },
      "source": [
        "# Dropping tweet column as it is no longer required for final submission leaving only the id column for identification\n",
        "df1 = df1.drop(['tweet'],axis=1)\n",
        "print(df1.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0    id  tweet_len_total  punc_len\n",
            "0           0  7921               77         6\n",
            "1           1  7922              115        13\n",
            "2           2  7923              104         9\n",
            "3           3  7924              129         4\n",
            "4           4  7925               70         6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCaBmeiDG8dE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ecfd751-2953-4fef-8ac1-de7626f4ca70"
      },
      "source": [
        "# Loading corresponding test tweets embeddings as loaded for the training dataset\n",
        "pickle_in = open(\"Spacy_bert_elmo_test.pickle\",\"rb\")\n",
        "test_X = pickle.load(pickle_in)\n",
        "print(test_X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1953, 2092)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeDnWamWG-v7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ecbf95a0-b104-4494-be41-6cfa157ca9c8"
      },
      "source": [
        "# Preparing test dataset for predictions by adding text features to the tweet embeddings data as it was done for training dataset \n",
        "tweet_len_arr_test = np.array(df1['tweet_len_total'])\n",
        "tweet_punct_arr_test = np.array(df1['punc_len'])\n",
        "print(tweet_len_arr_test.shape, tweet_punct_arr_test.shape)\n",
        "\n",
        "tweet_len_norm_test = mms.fit_transform(tweet_len_arr_test.reshape(-1, 1))\n",
        "tweet_punct_norm_test = mms.fit_transform(tweet_punct_arr_test.reshape(-1, 1))\n",
        "print(tweet_len_norm_test.shape, tweet_punct_norm_test.shape)\n",
        "\n",
        "test_X = np.hstack((test_X, tweet_len_norm_test, tweet_punct_norm_test))\n",
        "print(test_X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1953,) (1953,)\n",
            "(1953, 1) (1953, 1)\n",
            "(1953, 2094)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws4iE8WmHJNw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "392f3b44-7241-4075-a0c4-b4c67bdd4e17"
      },
      "source": [
        "# Making predictions using trained model for the test dataset for final submission \n",
        "test_predictions = text_clf.predict(test_X)\n",
        "print(test_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 0 ... 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "offo0E7mIXvZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3600bf30-5311-43ed-9368-2472c0ddc184"
      },
      "source": [
        "df1.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'id', 'tweet_len_total', 'punc_len', 'label'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv7FTlKwIIdU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "940e05f2-1211-45f0-bdf5-40166cd36232"
      },
      "source": [
        "\n",
        "# Adding predicted labels to the test dataframe\n",
        "df1['label'] = test_predictions\n",
        "df1.drop(['Unnamed: 0','tweet_len_total', 'punc_len'],axis=1,inplace=True)\n",
        "print(df1.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     id  label\n",
            "0  7921      1\n",
            "1  7922      1\n",
            "2  7923      0\n",
            "3  7924      1\n",
            "4  7925      1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nROLtslNIKR2"
      },
      "source": [
        "# Saving the final predicted submission file to csv\n",
        "df1.to_csv('ALL_SVM.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gM-TwERIMua"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}